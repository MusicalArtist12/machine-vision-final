% Julia Abdel-Monem, 2025

\documentclass[12pt]{article}

\usepackage[left=1in, right=1in, top=1in, bottom=1in]{geometry}
\usepackage{fancyhdr}
\usepackage[export]{adjustbox}
\usepackage[most]{tcolorbox}
\usepackage[bottom]{footmisc}
\usepackage{setspace}
\usepackage[document]{ragged2e}

\tolerance=1
\emergencystretch=\maxdimen
\hyphenpenalty=10000
\hbadness=10000
\renewcommand{\baselinestretch}{1.5}

\newtcolorbox{myframe}[1][]{
  enhanced,
  arc=0pt,
  outer arc=0pt,
  colback=white,
  boxrule=0.8pt,
  #1
}

\newcommand{\diagram}[1]{
    \begin{myframe}
        \includegraphics[width = 6in]{#1}
    \end{myframe}
}

\title{CS455 Final Project}
\author{Julia Abdel-Monem}
\date{March 31, 2025}

\begin{document}
    \maketitle

    \section*{Abstract}


    \section{Introduction}

    \subsection*{Background}

    \subsubsection*{Tailgating}

    According to the NHTSA in 2022, speeding accounted for 29\% of accident related fatalities, and 7.8\% of all fatalities involved at least one distracted driver \cite{NHTSA:Overview-2022}. While there are strategies to avoid crashes with an inattentive or aggressive driver, three studies released by the highway loss data institute (Subaru EyeSight, Kia Drive Wise, and Honda FCW/LDW) demonstrate that crash avoidance features may reduce the number of collision claims made, with young drivers experiencing the most benefit \cite{HLDI:SubaruEyeSight, HLDI:KiaDriveWise, HLDI:HondaFCW}. While the elderly population must still be considered, this trend in age may be explained by overall trends \cite{NHTSA:Overview-2022}. Newer cars are more expensive, so the goal of this project is to develop an app to help lower the financial barrier of entry from a modern car to a relatively recently made smartphone.

    \subsubsection*{Semantic Segmentation}

    Semantic segmentation was chosen since it provides an accurate width, without being overly complex to use. An object detection model such as YOLO would be useful in finding which cars are in front of the camera, but an accurate width requires an accurate edge to read against. instance detection may be useful for this, but it may have more overhead compared to semantic segmentation, where individual cars can be isolated by the width of the lane.

    \subsection*{Neural Network: Design and Training}

    \subsubsection*{The SegFormer}

    The SegFormer is a neural network designed to use vision transformers in semantic segmentation, using multiple transformers using an efficient self attention algorithm and a simple MLP decoder \cite{DBLP:journals/corr/abs-2105-15203}. It builds upon the original patch transformer encoder described in \cite{DBLP:journals/corr/abs-2010-11929}. This hierarchical transformer encoder extracts both coarse and fine features. The original SegFormer paper provides five different levels of preconfigured hyperparameters, each one taking more computational power but resulting in a higher IoU.

    \subsubsection*{Intersection over Union}

    To test the model's accuracy, the metric \texttt{Intersection over Union}, also known as IoU was chosen. Since there are only two classes that the model is being trained for (Car or Not Car), the BinaryIoU keras metric was chosen, comparing against both the 'Car' class ($\text{IoU}_1$) and the mean of both (mIoU). It is worth noting that the original design and experiment used mean IoU to validate training.

    \[
        \text{IoU}_i = \frac{\text{True Positives}_i}{\text{True Positives}_i + \text {False Positives}_i + \text{False Negatives}_i} = \frac{T_i \cap P_i}{T _i\cup P_i}
    \]


    \[
        \text{mIoU} = \frac{1}{c}\sum_{i=0}^{c}(\text{IoU}_i)
    \]

    \subsubsection*{Hyperparameters}

    \begin{center}
        \begin{tabular}{| l | r |}
            \hline
            \textbf{Hyperparameter} & \textbf{Explanation} \\
            \hline
            MiT series & MiT-B0 through MiT-B5, see \cite{DBLP:journals/corr/abs-2105-15203}. \\
            \hline
            Batch Size & Largely dependent on system memory. \\
            \hline
            Gradient Accumulation Steps & permits the use of a smaller batch size. \\
            \hline
            Image Resolution & A smaller resolution allows for a larger direct batch \\ & size and faster processing. \\
            \hline
        \end{tabular}
    \end{center}

    \section{Methods}

    \subsection*{Neural Network}

    \subsubsection*{Implementation Details}

    The neural network was implemented from scratch using Tensorflow and Keras in Python, based off of the SegFormer paper \cite{DBLP:journals/corr/abs-2105-15203}, the Vision Transformer paper \cite{ DBLP:journals/corr/abs-2010-11929}, and the original Attention paper \cite{DBLP:journals/corr/VaswaniSPUJGKP17}\footnote{\textit{Note to grader, this took the majority of the project time. I did not know what I was getting myself into.}}. This was done in order to use Tensorflow and Keras, as there are no working implementations of a SegFormer in Keras 3\footnote{I did find one written in Keras 2, which may have been upgraded to Keras 3, but I could not get it working. You can find it at github.com/IMvision12/SegFormer-tf/}. The original paper implemented their neural network in \textit{mmsegmentation} and PyTorch, and was one of the sources I used to implement my own, especially when it came to implementing the efficient self attention.

    This project overwhelmingly used classes that inherited from \texttt{keras.Model} for every single layer since Keras does not permit multiple layers of inheriting \texttt{keras.layers.Layer} (as in, the \texttt{TransformerBlock} must be a \texttt{keras.Model} if it uses any layers implemented by the end user, or it will not "see" or train those weights).


    \subsection*{Dataset}

    The dataset was trained on a subset Berkeley DeepDive 100K dataset, modified to only include one class. There is no existing implementation of this dataset for Tensorflow, so to allow the efficient use of the dataset, a Tensorflow dataset was constructed using \texttt{tfds}. This dataset was chosen for its size and spread among a diverse set of environments.

    \subsection*{Training (and Finding the Correct Loss Function)}

    \section{Results}

    \subsection*{Binary CrossEntropy, Binary IoU, B0}

    \subsection*{Dice Loss, Binary IoU, no axis set, B0}

    \subsection*{Dice Loss, Binary IoU, Downscaled images, B2}

    \subsection*{Tversky Loss, Binary IoU, Downscaled images, B0}

    \section{Conclusion}

    \newpage
    \bibliographystyle{apalike}
    \bibliography{refs} % Entries are in the refs.bib file


\end{document}